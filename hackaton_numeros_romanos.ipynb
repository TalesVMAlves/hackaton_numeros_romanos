{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb930183",
   "metadata": {
    "id": "eb930183"
   },
   "source": [
    "# Hackathon: The AED Challenge\n",
    "\n",
    "Our Hackathon project focus on Annotation Error Detection (AED) for machine learning datasets. The goal is to identify and correct errors in the annotations of datasets used for training machine learning models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3360070a",
   "metadata": {
    "id": "3360070a"
   },
   "source": [
    "\n",
    "## üéØ Goals\n",
    "\n",
    "Your goal is to build an automated method to detect incorrectly labeled images in a **training dataset**. You will be evaluated on how many label errors you can correctly identify.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6762a4c7",
   "metadata": {
    "id": "6762a4c7"
   },
   "source": [
    "\n",
    "## üìÅ Datasets\n",
    "\n",
    "You will be provided with two main datasets:\n",
    "\n",
    "1.  **Training Set (`training_set`)**\n",
    "    *   **Contents**: A collection of images and their corresponding labels.\n",
    "    *   **The Catch**: This set contains an unknown number of labeling errors. You **do not** have the ground truth for which labels are incorrect.\n",
    "    *   **Your Goal**: This is the dataset you must analyze. Your final submission will be a list of suspected errors from this set.\n",
    "\n",
    "2.  **Validation Set (`validation_set`)**\n",
    "    *   **Contents**: A smaller collection of images, their labels, and a special ground truth column (`is_noisy`).\n",
    "    *   **Purpose**: This set is your sandbox. You can use it to develop, test, and validate your error detection models and algorithms. The `is_noisy` column will tell you exactly which labels are wrong (`1`) and which are correct (`0`), allowing you to measure your method's performance before applying it to the real challenge.\n",
    "\n",
    "The original dataset comes from [this hackathon](https://https-deeplearning-ai.github.io/data-centric-comp/) by Andrew Ng and the Deeplearning.ai team."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d64698c",
   "metadata": {
    "id": "3d64698c"
   },
   "source": [
    "\n",
    "## üìù Your Task\n",
    "\n",
    "1.  **Explore the Data**: Start by analyzing both the `training_set` and `validation_set`. Understand the classes, image characteristics, and potential sources of error.\n",
    "2.  **Develop Your Method**: Use the `validation_set` to build and refine your strategy. You could train a model and look for low-confidence predictions, analyze feature embeddings to find outliers, or use other clever techniques.\n",
    "3.  **Identify Errors in the Training Set**: Once you are confident in your method, apply it to the `training_set` to predict which items have incorrect labels.\n",
    "4.  **Generate a Submission File**: Create a CSV file detailing your findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f13336d",
   "metadata": {
    "id": "6f13336d"
   },
   "source": [
    "\n",
    "## üöÄ Submission\n",
    "\n",
    "Your final output must be a single CSV file named `submission.csv`. This file will be uploaded to the online judging platform.\n",
    "\n",
    "For your grades,  you'll also need to upload your work to a GitHub repository. The repository should include:\n",
    "-   Your code for the error detection method.\n",
    "-   A README file explaining your approach, how to run your code, and any dependencies.\n",
    "-   Any additional files or scripts that are necessary to reproduce your results.\n",
    "\n",
    "## üìÖ Timeline\n",
    "-   **Start Time**: 2025-06-26 - 19:00\n",
    "-   **End Time**: 2025-06-26 - 21:30\n",
    "-   **Submission Deadline**: 2025-06-26 - 21:30\n",
    "-   **SIGAA Submission Deadline**: 2025-06-27 - 23:59\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860c9a3a",
   "metadata": {
    "id": "860c9a3a"
   },
   "source": [
    "\n",
    "### Submission File Format\n",
    "\n",
    "The CSV file must contain exactly two columns: `uid` and `is_noisy`.\n",
    "\n",
    "*   `uid`: The identifier/filename of the image from the `training_set`.\n",
    "*   `is_noisy`: Your prediction. Use `1` if you believe the label is an error, and `0` if you believe it is correct.\n",
    "\n",
    "**Example `submission.csv`:**\n",
    "\n",
    "```csv\n",
    "uid,is_noisy\n",
    "12345676890aed,0\n",
    "12345676890aee,1\n",
    "12345676890aef,0\n",
    "12345676890af0,1\n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc5d200",
   "metadata": {
    "id": "3bc5d200"
   },
   "source": [
    "\n",
    "## üèÜ Evaluation\n",
    "\n",
    "Your submission will be evaluated using the **Matthews Correlation Coefficient (MCC)**.\n",
    "\n",
    "*   **Why MCC?**: MCC is a robust metric for binary classification that performs well even when the classes are highly imbalanced (as we expect far more correct labels than incorrect ones). It provides a single, balanced score that accounts for true/false positives and negatives.\n",
    "*   **The Winner**: The team with the highest MCC score on the hidden ground truth of the `training_set` wins!\n",
    "*   **Your Grade**: Your grade will be based on the quality of your submission on SIGAA.\n",
    "\n",
    "The final **leaderboard** on the platform will show your rank and score after each submission.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AQbvU7KLU7Rs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AQbvU7KLU7Rs",
    "outputId": "a6c98d0c-c9cc-4a1c-cc64-309972a452ef"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install Pillow\n",
    "!pip install numpy\n",
    "!pip install joblib\n",
    "!pip install pathlib\n",
    "!pip install tqdm\n",
    "!pip install cleanlab[datalab]\n",
    "!pip install matplotlib\n",
    "!pip install plotly\n",
    "!pip install xgboost\n",
    "!pip install cleanvision\n",
    "!pip install seaborn\n",
    "!pip install --extra-index-url https://download.pytorch.org/whl/cu128\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install torchaudio\n",
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7893a082",
   "metadata": {
    "id": "7893a082"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "# Download the dataset from the provided URL\n",
    "url_train = 'https://public.jacob.al/imd3011-datacentric_ai/hackathon-2025-2/train_no_labels.json.gz'\n",
    "url_valid = 'https://public.jacob.al/imd3011-datacentric_ai/hackathon-2025-2/valid.json.gz'\n",
    "\n",
    "response_train = requests.get(url_train)\n",
    "response_valid = requests.get(url_valid)\n",
    "\n",
    "# Read the JSON data into pandas DataFrames\n",
    "train_data = pd.read_json(io.BytesIO(response_train.content), compression='gzip')\n",
    "valid_data = pd.read_json(io.BytesIO(response_valid.content), compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814c1a7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "814c1a7a",
    "outputId": "dba8d178-ef1f-4f16-966f-79788621b3a3"
   },
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e744741b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "e744741b",
    "outputId": "41e78380-fcee-443d-814c-c995984bf7e0"
   },
   "outputs": [],
   "source": [
    "valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hD4JezVJX7Rm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hD4JezVJX7Rm",
    "outputId": "f3160195-4f70-495c-87b3-45c089163f8b"
   },
   "outputs": [],
   "source": [
    "len(valid_data[valid_data.is_noisy == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56848aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "b56848aa",
    "outputId": "676b3ec6-4dac-4ef4-93d9-66a2ee244d23"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def show_image_from_np_array(np_array):\n",
    "    np_array = np.array(np_array, dtype=np.uint8)  # Ensure the array is in the correct format\n",
    "    image = Image.fromarray(np_array)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')  # Hide the axis\n",
    "    plt.show()\n",
    "\n",
    "# Display the first image from the training dataset\n",
    "show_image_from_np_array(train_data['image'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66d9116",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "d66d9116",
    "outputId": "646a32da-5fde-4cc3-cc7e-89b47cf69766"
   },
   "outputs": [],
   "source": [
    "valid_data.query('is_noisy == True').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xcUoPdIrS_sB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "xcUoPdIrS_sB",
    "outputId": "ce793fc7-b233-4e3c-9cd8-1a69000472ad"
   },
   "outputs": [],
   "source": [
    "train_data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110ac98d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "110ac98d",
    "outputId": "9d81c83d-dd09-4f2a-d485-ee7488843ac0"
   },
   "outputs": [],
   "source": [
    "row = valid_data.query('is_noisy == True').sample(1).iloc[0]\n",
    "\n",
    "show_image_from_np_array(row['image'])\n",
    "print(row['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bc6756",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "f2bc6756",
    "outputId": "5c994973-475f-4a1f-8932-cabf2a31dca1"
   },
   "outputs": [],
   "source": [
    "row = valid_data.query('is_noisy == True').sample(1).iloc[0]\n",
    "\n",
    "show_image_from_np_array(row['image'])\n",
    "print(row['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3590da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "af3590da",
    "outputId": "ee98b243-633a-445c-acda-dd0abb49b77b"
   },
   "outputs": [],
   "source": [
    "row = valid_data.query('is_noisy == True').sample(1).iloc[0]\n",
    "\n",
    "show_image_from_np_array(row['image'])\n",
    "print(row['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4389c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "0b4389c3",
    "outputId": "cc3c03c9-a65c-4d7d-bca0-99e0059b085e"
   },
   "outputs": [],
   "source": [
    "row = valid_data.query('is_noisy == True').sample(1).iloc[0]\n",
    "\n",
    "show_image_from_np_array(row['image'])\n",
    "print(row['label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992673c0",
   "metadata": {},
   "source": [
    "## Gera√ß√£o dos Embeddings\n",
    "\n",
    "Essa foi a etapa que mais nos atrapalhou.\n",
    "\n",
    "Nos faltou experi√™ncia em problemas de vis√£o computacional, estavamos acostumado a ter um dataset de imagens e n√£o em formato RGB.\n",
    "\n",
    "A nossa estrat√©gia foi identificar a maior imagem e fazer um padding nas demais. Olhando agora esse padding tamb√©m poderia ter sido feito com um cuidado maior, utilizamos o 0, para fazer o padding, por√©m como o RGB de 0, 0 , 0 estava sendo utilizado para os digitos romanos pode ter gerado uma confus√£o ao fazer os embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YzbWu8-RhE3b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YzbWu8-RhE3b",
    "outputId": "8325e337-de06-4049-c5ff-9add5738169a"
   },
   "outputs": [],
   "source": [
    "max_length = max(train_data['image'].apply(len))\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "J_89jcSRgbd_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J_89jcSRgbd_",
    "outputId": "5707f4e4-3e80-4f9e-a6a6-d839504a7796"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "model = AutoModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "TARGET_SIZE = 648 \n",
    "IMG_SHAPE = (18, 12)  \n",
    "\n",
    "def extract_embedding_from_pixels(pixel_lists):\n",
    "    embeddings = []\n",
    "    for i, pixels in enumerate(tqdm(pixel_lists)):\n",
    "        try:\n",
    "            pixels_array = np.array(pixels, dtype=np.uint8)\n",
    "\n",
    "            if pixels_array.size < TARGET_SIZE:\n",
    "                pixels_array = np.pad(pixels_array, (0, TARGET_SIZE - pixels_array.size), 'constant')\n",
    "            elif pixels_array.size > TARGET_SIZE:\n",
    "                pixels_array = pixels_array[:TARGET_SIZE]\n",
    "\n",
    "            if pixels_array.size != TARGET_SIZE:\n",
    "                 pixels_array = np.array(pixels, dtype=np.uint8).flatten()\n",
    "                 if pixels_array.size < TARGET_SIZE:\n",
    "                     pixels_array = np.pad(pixels_array, (0, TARGET_SIZE - pixels_array.size), 'constant')\n",
    "                 else:\n",
    "                     pixels_array = pixels_array[:TARGET_SIZE]\n",
    "\n",
    "            reshaped_array = pixels_array.reshape((*IMG_SHAPE, 3))\n",
    "\n",
    "            img = Image.fromarray(reshaped_array, mode=\"RGB\")\n",
    "\n",
    "            img = img.resize((224, 224))\n",
    "\n",
    "            inputs = processor(images=img, return_tensors=\"pt\")\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "            feature_vector = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "            embeddings.append(feature_vector)\n",
    "\n",
    "        except ValueError as ve:\n",
    "            print(f\"ValueError at index {i}: {ve}. Pixels array shape: {pixels_array.shape if 'pixels_array' in locals() else 'N/A'}\")\n",
    "            embeddings.append(np.zeros(model.config.hidden_size))\n",
    "        except Exception as e:\n",
    "            print(f\"General error at index {i}: {e}\")\n",
    "            embeddings.append(np.zeros(model.config.hidden_size))\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tSyVg08Ygdjn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tSyVg08Ygdjn",
    "outputId": "25f0b2a1-8991-4683-982a-58b9e7944e80"
   },
   "outputs": [],
   "source": [
    "train_embeddings = extract_embedding_from_pixels(train_data['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9899cd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79298f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_embeddings = extract_embedding_from_pixels(valid_data['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce6e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_embeddings\n",
    "y_train = train_data.label\n",
    "\n",
    "X_valid = val_embeddings\n",
    "y_valid = valid_data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d93927",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80844bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17afce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = y_train.unique().tolist()\n",
    "\n",
    "class_to_idx = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "idx_to_class = {i: name for name, i in class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4afce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b121160",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22427d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['class_idx'] = train_data['label'].map(class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be9aaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.class_idx.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2e08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(16, 22))\n",
    "ax = sns.countplot(y=train_data['class_idx'], order=train_data['class_idx'].value_counts().index)\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Class Label')\n",
    "plt.title('Distribution of Numbers')\n",
    "\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()    \n",
    "    plt.text(width + 1,       \n",
    "             p.get_y() + p.get_height()/2.,\n",
    "             f'{int(width)}', \n",
    "             ha='left',       \n",
    "             va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e74b74",
   "metadata": {},
   "source": [
    "## Cleanlab\n",
    "\n",
    "Pela simplicidade optamos por explorar o Cleanlab para identificar poss√≠veis outliers.\n",
    "\n",
    "Ele gerou uma amostra de 10% do conjunto, por√©m todos com um score 0.0, por isso acamos desconsiderando. O near duplicate tamb√©m foi utilizado, mas assim como no de outliers todos os scores foram 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10a4290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab import Datalab\n",
    "\n",
    "lab = Datalab(data=train_data)\n",
    "\n",
    "lab.find_issues(features=X_train, issue_types={\"near_duplicate\": {}, \"outlier\": {}})\n",
    "\n",
    "lab.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab6531",
   "metadata": {},
   "outputs": [],
   "source": [
    "near_duplicates = lab.get_issues(\"near_duplicate\").query(\"is_near_duplicate_issue == True\")\n",
    "\n",
    "outliers = lab.get_issues(\"outlier\").query(\"is_outlier_issue == True\")\n",
    "\n",
    "near_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b313f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the outliers DataFrame by the 'outlier_score' column in ascending order\n",
    "# This helps in identifying the most significant outliers first\n",
    "outliers = outliers.sort_values(\"outlier_score\", ascending=True)\n",
    "\n",
    "# Display the sorted outliers DataFrame\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de352dd7",
   "metadata": {},
   "source": [
    "Mesmo assim observamos alguns exemplos utilizando o Index que o cleanlab havia encontrado, e como esper√°vamos s√£o amostras completamente aleat√≥rias, grande parte delas estavam corretamente classificadas, e uma pequena parte eram outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e3149",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = 1431"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e3d562",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_from_np_array(train_data['image'][NUMBER])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65492268",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.iloc[NUMBER]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac57761",
   "metadata": {},
   "source": [
    "## ReCov\n",
    "\n",
    "O √∫ltimo algoritmo que conseguimos utilizar foi o ReCov, estudamos ele e implementamos anterior a essa atividade e conseguimos aplicar ao conjunto de dados. \n",
    "\n",
    "O objetivo desse algoritmo √© identificar as amostras ruidosas durante o cross validation, a partir do desempenho do modelo.\n",
    "\n",
    "Essa foi a estrat√©gia que utilizamos para filtrar o conjunto de treino.\n",
    "\n",
    "Removemos todos os √≠ndices encontrados pelo ReCov, o maior motivo dessa abordagem bruta foi a falta de tempo no final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eae9231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "def recov(X, y, model, n_runs=100, k_folds=5, random_state=None):\n",
    "    n_samples = len(X)\n",
    "    occurrence_counts = np.zeros(n_samples)\n",
    "    \n",
    "    for run in range(n_runs):\n",
    "        kf = KFold(n_splits=k_folds, shuffle=True, random_state=random_state + run if random_state is not None else None)\n",
    "        fold_val_scores = []\n",
    "        fold_indices = []\n",
    "        \n",
    "        models = []\n",
    "        for train_idx, val_idx in kf.split(X):\n",
    "            X_train, X_val = X[train_idx], X[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "            \n",
    "            fold_model = clone(model)\n",
    "            fold_model.fit(X_train, y_train)\n",
    "            models.append(fold_model)\n",
    "            fold_indices.append(val_idx)\n",
    "            \n",
    "            score = fold_model.score(X_val, y_val)\n",
    "            fold_val_scores.append(score)\n",
    "        \n",
    "        worst_fold_idx = np.argmin(fold_val_scores)\n",
    "        worst_fold_samples = fold_indices[worst_fold_idx]\n",
    "        \n",
    "        occurrence_counts[worst_fold_samples] += 1\n",
    "    \n",
    "    return occurrence_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee279256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "occurrence_counts = recov(X_train, y_train, model, n_runs=100, k_folds=5)\n",
    "\n",
    "noisy_indices = np.argsort(occurrence_counts)[-int(0.1 * len(X_train)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac7b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4045ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_from_np_array(train_data['image'][18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.iloc[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd269cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a63413",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission['is_noisy'] = False\n",
    "\n",
    "final_submission.loc[noisy_indices, 'is_noisy'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb9e8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_submission.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad7a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission = final_submission[['uid', 'is_noisy']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241b1877",
   "metadata": {},
   "source": [
    "## Estrat√©gias que n√£o conseguimos utilizar\n",
    "\n",
    "Um dos erros que cometemos foi n√£o fazer um modelo simples utilizando todo o conjunto de treinamento e utilizar os n√≠veis de confian√ßa, como vimos em aula, n√£o esper√°vamos passar tanto tempo sofrendo com a produ√ß√£o dos embeddings.\n",
    "\n",
    "Isso iria ajudar bastante j√° que poder√≠amos utilizar a confian√ßa do modelo como guia para a sele√ß√£o das imagens, uma estrat√©gia, eficiente e f√°cil de ser implementada.\n",
    "\n",
    "Al√©m disso perdemos a oportunidade em n√£o utilizar um servi√ßo de LLM para classificar as imagens, acredito que essa seria uma solu√ß√£o criativa e decente em identificar poss√≠veis erros de r√≥tulos, caso houvesse conflitos entre os r√≥tulos da LLM e os do Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c68e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, classification_report,\n",
    "    confusion_matrix, f1_score, matthews_corrcoef\n",
    ")\n",
    "from typing import List, Tuple\n",
    "\n",
    "def calculate_evaluation_metrics(y_true: pd.Series, y_pred: pd.Series) -> Tuple[float, float, float, str, float, np.ndarray]:\n",
    "    f1 = f1_score(y_true, y_pred, average='micro')\n",
    "    balanced_accuracy = balanced_accuracy_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    classification_report_str = classification_report(y_true, y_pred)\n",
    "    matthews_corr_coeff = matthews_corrcoef(y_true, y_pred)\n",
    "    confusion_matrix_arr = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    return f1, balanced_accuracy, accuracy, classification_report_str, matthews_corr_coeff, confusion_matrix_arr\n",
    "\n",
    "def train_and_evaluate_logistic_regression(X_train: pd.DataFrame,\n",
    "                                           y_train: pd.Series,\n",
    "                                           X_valid: pd.DataFrame,\n",
    "                                           y_valid: pd.Series) -> Tuple[pd.DataFrame, List[List]]:\n",
    "    model_name = 'LogisticRegression'\n",
    "    model = LogisticRegression(random_state=1408, n_jobs=-1, class_weight='balanced', max_iter=1000)\n",
    "\n",
    "    evaluation_results = []\n",
    "    classification_reports = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_valid)\n",
    "\n",
    "    f1, balanced_accuracy, accuracy, classification_report_str, matthews_corr_coeff, confusion_matrix_arr = calculate_evaluation_metrics(y_valid, predictions)\n",
    "    classification_reports.append([model_name, classification_report_str, confusion_matrix_arr])\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    evaluation_results.append([model_name, f1, balanced_accuracy, accuracy, matthews_corr_coeff, elapsed_time, confusion_matrix_arr, classification_report_str])\n",
    "\n",
    "    print(f'Name: {model_name} - F1: {f1:.4f} - BACC: {balanced_accuracy:.4f} - ACC: {accuracy:.4f} - MCC: {matthews_corr_coeff:.4f} - Elapsed: {elapsed_time:.2f}s')\n",
    "    print(classification_report_str)\n",
    "    print(confusion_matrix_arr)\n",
    "    print('*' * 20, '\\n')\n",
    "\n",
    "    results_df = pd.DataFrame(evaluation_results, columns=['Model', 'F1', 'BACC', 'ACC', 'MCC', 'Total Time', 'Confusion Matrix', 'Classification Report'])\n",
    "    results_df['Confusion Matrix'] = results_df['Confusion Matrix'].apply(str)\n",
    "\n",
    "    return results_df, classification_reports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa56c3c",
   "metadata": {},
   "source": [
    "## üöÄ Submission\n",
    "\n",
    "Your final output must be a single CSV file named `submission.csv`. This file will be uploaded to the online judging platform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550ac7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission.head(2) # Replace with your final submission file path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12843bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8359fa34",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
